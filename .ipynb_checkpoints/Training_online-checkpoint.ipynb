{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training models on FER2013 with PyTorch\n",
    "# 10 crop for data enhancement\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import transforms as transforms\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "import utils\n",
    "import csv\n",
    "import time\n",
    "from fer import FER2013\n",
    "from torch.autograd import Variable\n",
    "from models import *\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add arguement & Parameter setting\n",
    "parser = argparse.ArgumentParser(description='PyTorch Fer2013 CNN Training')\n",
    "parser.add_argument('--model', type=str, default='VGG19', help='CNN architecture')\n",
    "parser.add_argument('--dataset', type=str, default='FER2013', help='dataset Name')\n",
    "parser.add_argument('--bs', default=128, type=int, help='batch size')\n",
    "parser.add_argument('--lr', default=0.01, type=float, help='learning rate')\n",
    "parser.add_argument('--ep', default=250, type=int, help='total epoch')\n",
    "parser.add_argument('--cs', default=44, type=int, help='cut size')\n",
    "parser.add_argument('--resume', '-r', action='store_true', help='resume from checkpoint')\n",
    "opt = parser.parse_args()\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "best_PublicTest_acc = 0  # best PublicTest accuracy\n",
    "best_PublicTest_acc_epoch = 0\n",
    "best_PrivateTest_acc = 0  # best PrivateTest accuracy\n",
    "best_PrivateTest_acc_epoch = 0\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "learning_rate_decay_start = 80  # 50\n",
    "learning_rate_decay_every = 5 # 5\n",
    "learning_rate_decay_rate = 0.9 # 0.9\n",
    "\n",
    "cut_size = opt.cs\n",
    "total_epoch = opt.ep\n",
    "# Default: FER2013_VGG19_250\n",
    "path = os.path.join(opt.dataset + '_' + opt.model+'_Ep'+str(opt.ep))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(cut_size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.TenCrop(cut_size),\n",
    "    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
    "])\n",
    "\n",
    "Trainingset = FER2013(split = 'Training', transform=transform_train)\n",
    "Trainingloader = torch.utils.data.DataLoader(Trainingset, batch_size=opt.bs, shuffle=True, num_workers=1)\n",
    "PublicTestset = FER2013(split = 'PublicTest', transform=transform_test)\n",
    "PublicTestloader = torch.utils.data.DataLoader(PublicTestset, batch_size=opt.bs, shuffle=False, num_workers=1)\n",
    "PrivateTestset = FER2013(split = 'PrivateTest', transform=transform_test)\n",
    "PrivateTestloader = torch.utils.data.DataLoader(PrivateTestset, batch_size=opt.bs, shuffle=False, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model selction\n",
    "if opt.model  == 'Resnet18':\n",
    "    net = ResNet18()\n",
    "else:\n",
    "    net = VGG(opt.model)\n",
    "\n",
    "if opt.resume:\n",
    "    # Load checkpoint.\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    assert os.path.isdir(path), 'Error: no checkpoint directory found!'\n",
    "    checkpoint = torch.load(os.path.join(path,'PrivateTest_model.t7'))\n",
    "\n",
    "    net.load_state_dict(checkpoint['net'])\n",
    "    best_PublicTest_acc = checkpoint['best_PublicTest_acc']\n",
    "    best_PrivateTest_acc = checkpoint['best_PrivateTest_acc']\n",
    "    best_PrivateTest_acc_epoch = checkpoint['best_PublicTest_acc_epoch']\n",
    "    best_PrivateTest_acc_epoch = checkpoint['best_PrivateTest_acc_epoch']\n",
    "    start_epoch = checkpoint['best_PrivateTest_acc_epoch'] + 1\n",
    "else:\n",
    "    print('==> Building model..')\n",
    "\n",
    "if use_cuda:\n",
    "    net.cuda()\n",
    "# Creterion and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=opt.lr, momentum=0.9, weight_decay=5e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    global Train_acc\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    if epoch > learning_rate_decay_start and learning_rate_decay_start >= 0:\n",
    "        frac = (epoch - learning_rate_decay_start) // learning_rate_decay_every\n",
    "        decay_factor = learning_rate_decay_rate ** frac\n",
    "        current_lr = opt.lr * decay_factor\n",
    "        utils.set_lr(optimizer, current_lr)  # set the decayed rate\n",
    "    else:\n",
    "        current_lr = opt.lr\n",
    "    #print('learning_rate: %s' % str(current_lr))\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(Trainingloader):\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = Variable(inputs), Variable(targets)\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        utils.clip_gradient(optimizer, 0.1)\n",
    "        optimizer.step()\n",
    "        train_loss += loss.data[0]\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.data).cpu().sum()\n",
    "\n",
    "        '''utils.progress_bar(batch_idx, len(Trainingloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "            % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))'''\n",
    "\n",
    "    Train_acc = 100.*correct/total\n",
    "\n",
    "def PublicTest(epoch):\n",
    "    global PublicTest_acc\n",
    "    global best_PublicTest_acc\n",
    "    global best_PublicTest_acc_epoch\n",
    "    net.eval()\n",
    "    PublicTest_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(PublicTestloader):\n",
    "        bs, ncrops, c, h, w = np.shape(inputs)\n",
    "        inputs = inputs.view(-1, c, h, w)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = Variable(inputs, volatile=True), Variable(targets)\n",
    "        outputs = net(inputs)\n",
    "        outputs_avg = outputs.view(bs, ncrops, -1).mean(1)  # avg over crops\n",
    "        loss = criterion(outputs_avg, targets)\n",
    "        PublicTest_loss += loss.data[0]\n",
    "        _, predicted = torch.max(outputs_avg.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.data).cpu().sum()\n",
    "\n",
    "        '''utils.progress_bar(batch_idx, len(PublicTestloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                           % (PublicTest_loss / (batch_idx + 1), 100. * correct / total, correct, total))'''\n",
    "\n",
    "    # Save checkpoint.\n",
    "    PublicTest_acc = 100.*correct/total\n",
    "    if PublicTest_acc > best_PublicTest_acc:\n",
    "        #print('Saving..')\n",
    "        #print(\"best_PublicTest_acc: %0.3f\" % PublicTest_acc)\n",
    "        state = {\n",
    "            'net': net.state_dict() if use_cuda else net,\n",
    "            'acc': PublicTest_acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir(path):\n",
    "            os.mkdir(path)\n",
    "        torch.save(state, os.path.join(path,'PublicTest_model.t7'))\n",
    "        best_PublicTest_acc = PublicTest_acc\n",
    "        best_PublicTest_acc_epoch = epoch\n",
    "\n",
    "def PrivateTest(epoch):\n",
    "    global PrivateTest_acc\n",
    "    global best_PrivateTest_acc\n",
    "    global best_PrivateTest_acc_epoch\n",
    "    net.eval()\n",
    "    PrivateTest_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(PrivateTestloader):\n",
    "        bs, ncrops, c, h, w = np.shape(inputs)\n",
    "        inputs = inputs.view(-1, c, h, w)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = Variable(inputs, volatile=True), Variable(targets)\n",
    "        outputs = net(inputs)\n",
    "        outputs_avg = outputs.view(bs, ncrops, -1).mean(1)  # avg over crops\n",
    "        loss = criterion(outputs_avg, targets)\n",
    "        PrivateTest_loss += loss.data[0]\n",
    "        _, predicted = torch.max(outputs_avg.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.data).cpu().sum()\n",
    "\n",
    "        '''utils.progress_bar(batch_idx, len(PublicTestloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "            % (PrivateTest_loss / (batch_idx + 1), 100. * correct / total, correct, total))'''\n",
    "    # Save checkpoint.\n",
    "    PrivateTest_acc = 100.*correct/total\n",
    "\n",
    "    if PrivateTest_acc > best_PrivateTest_acc:\n",
    "        #print('Saving..')\n",
    "        #print(\"best_PrivateTest_acc: %0.3f\" % PrivateTest_acc)\n",
    "        state = {\n",
    "            'net': net.state_dict() if use_cuda else net,\n",
    "            'best_PublicTest_acc': best_PublicTest_acc,\n",
    "            'best_PrivateTest_acc': PrivateTest_acc,\n",
    "            'best_PublicTest_acc_epoch': best_PublicTest_acc_epoch,\n",
    "            'best_PrivateTest_acc_epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir(path):\n",
    "            os.mkdir(path)\n",
    "        torch.save(state, os.path.join(path,'PrivateTest_model.t7'))\n",
    "        best_PrivateTest_acc = PrivateTest_acc\n",
    "        best_PrivateTest_acc_epoch = epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Part\n",
    "if not os.path.exists(path):    \n",
    "        os.makedirs(path)\n",
    "logfile = str(path) +\"/log.csv\"\n",
    "info = \"Traing model:\"+opt.model+\" Dataset:\"+opt.dataset+\" Total epoch:\"+str(opt.ep)\n",
    "begin = time.time()\n",
    "print(info)\n",
    "print(\"Writing log to:\",logfile)\n",
    "with open(logfile,\"w\") as Log: \n",
    "    record = csv.writer(Log)\n",
    "    record.writerow([\"Epoch\",\"Train_acc\",\"PublicTest_acc\",\"PrivateTest_acc\"])\n",
    "    \n",
    "    for epoch in range(start_epoch, total_epoch):\n",
    "        epoch_start = time.time()\n",
    "        train(epoch)\n",
    "        PublicTest(epoch)\n",
    "        PrivateTest(epoch)\n",
    "        log_data = [epoch,Train_acc, PublicTest_acc, PrivateTest_acc]\n",
    "        record.writerow(log_data)\n",
    "        print(\"Train_acc:%f PublicTest_acc:%f PrivateTest_acc:%f\"%(Train_acc,PublicTest_acc,PrivateTest_acc))\n",
    "        epoch_end = time.time()\n",
    "        epoch_time = epoch_end - epoch_start\n",
    "        program_time = epoch_end - begin\n",
    "        print(\"Epoch executing time:%.2f s    Program executing time:%.2f s.\"%(epoch_time,program_time))\n",
    "\n",
    "print(\"Training finished!!!\" )\n",
    "'''        \n",
    "print(\"best_PublicTest_acc: %0.3f\" % best_PublicTest_acc)\n",
    "print(\"best_PublicTest_acc_epoch: %d\" % best_PublicTest_acc_epoch)\n",
    "print(\"best_PrivateTest_acc: %0.3f\" % best_PrivateTest_acc)\n",
    "print(\"best_PrivateTest_acc_epoch: %d\" % best_PrivateTest_acc_epoch)\n",
    "'''\n",
    "bestlog = str(path) +\"/best_log.csv\"\n",
    "with open(bestlog,\"w\") as Bestlog: \n",
    "    bestrecord = csv.writer(Bestlog)\n",
    "    bestrecord.writerow([\"best_PublicTest_acc_epoch\",\"best_PublicTest_acc\",\n",
    "                         \"best_PrivateTest_acc_epoch\",\"best_PrivateTest_acc\"])\n",
    "    bestrecord.writerow([best_PublicTest_acc_epoch,best_PublicTest_acc,\n",
    "                         best_PrivateTest_acc_epoch,best_PrivateTest_acc])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
